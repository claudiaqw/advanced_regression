---
title: "Regresión Avanzada para la estimación de fallecidos de COVID-19"
author: "Claudia Quintana Wong"
date: "26/2/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introducción

Las tasas de letalidad ayudan a entender la gravedad de una enfermedad, a identificar las poblaciones en riesgo y a evaluar la calidad de la atención sanitaria. El objetivo de este trabajo es concebir y diseñar dos modelos, uno explicativo y otro predictivo, que nos permitan predecir la cantidad de muertes de COVID-19 en Estados Unidos en función de un conjunto de variables. Consiste en un problema de regresión pues la variable a predecir toma valores numéricos. Se recoge información de tres fuentes diferentes. Se tienen datos de casos reportes genéricos de COVID-19, de reportes de vacunación en los últimos meses y de casos diarios con diferenciación de raza y etnia.

```{r message=FALSE, echo=FALSE}

library(tidyverse)
library(MASS)
library(caret)
library(dplyr)
library(data.table)
library(corrplot)
library(GGally)
library(glmnet)
library(olsrr)
```

## Preparación de los datos

Partimos del conjunto de datos del ejercicio de GLM que fue tomado de https://covidtracking.com/data. Aplicamos los mismos filtros en la limpieza de información. Al incluir datos de vacunación en el análisis, solo se cuenta con dichos datos a partir del 24 de enero de 2021. Por esta razón, se ha decidido tomar solo los datos posteriores al 1ro de octubre de 2020 en la base de datos de casos diarios, para no tener desbalanceo respecto a los datos de vacunados.

```{r}
data <- read.csv(file = 'data/covid_data_us.csv')
data$Last_Update <- as.Date(data$Last_Update)
data$Date <- as.Date(data$Date)
data <- data %>% 
  dplyr::select(Province_State, Lat, Long_, Confirmed, Deaths, Recovered, Active, Incident_Rate, 
         Total_Test_Results, Case_Fatality_Ratio, 
         Testing_Rate, Date) %>% 
  dplyr::filter(Date >= "2020-10-01") %>% 
  dplyr::arrange(Date)
summary(data)
```
El conjunto de datos que muestra el proceso de vacunación en Estados Unidos fue tomado de https://github.com/COVID19Tracking/covid-tracking-data. Este repositorio de GitHub guarda información de la cantidad de personas vacunadas, diferenciado entre la primera y segunda dosis, y organizada según el estado y la fecha.

```{r}
vaccine.data <- read.csv('data/cdc_vaccinations_ltc_timeseries_daily.csv')
vaccine.data$Date <- as.Date(vaccine.data$Date)
vaccine.data <- vaccine.data %>% 
  dplyr::select(Date, Location, LongName, Census2019, Administered_Fed_LTC, Administered_Fed_LTC_Dose1, Administered_Fed_LTC_Dose2)
summary(vaccine.data)
```
 
```{r}
location.name = unique(vaccine.data[c('Location', 'LongName')])
covid.data <- merge(data, location.name, by.x = c('Province_State'), by.y=c('LongName'), all.x=TRUE)
merged.data <- merge(covid.data, vaccine.data, by.x = c('Location', 'Date'), by.y=c('Location', 'Date'), all.x=TRUE) 
merged.data <- merged.data[c(-14, -15)] 
```

```{r, echo=FALSE}
summary(merged.data)
```
El conjunto de fue tomado de The Covid Racial Data Tracker (https://covidtracking.com/race). En este *dataset* se han compilado los datos de raza y etnia que los estados reportan para varias categorías de datos de COVID-19. Contiene 54 variables de acuerdo a categorías de raza y etnia. En este caso, solo se preservan las columnas relacionadas con el color de la piel.

```{r, warning=FALSE}
etnicity.data <- read.csv('data/CRDT Data - CRDT.csv')
etnicity.data$Date <- as.character(etnicity.data$Date)
etnicity.data$Cases_Black <- as.numeric(etnicity.data$Cases_Black)
etnicity.data$Date <- as.Date(etnicity.data$Date, format = "%Y%m%d")
etnicity.data <- etnicity.data %>% 
  dplyr::select(Date, State, Cases_White, Cases_Black, Deaths_White, Deaths_Black, Hosp_Total, Hosp_White, Hosp_Black)
etnicity.data <- merge(etnicity.data, location.name, by.x = 'State', by.y='Location', all.x = TRUE)
```

Para evitar el sesgo en el análisis respecto al color de piel se incluye información étnica de todos los estados. Se adicionan variables que explican la población total y la cantidad de personas con piel de color blanca y negra.

```{r}
race.data <- read.csv('data/raw_data.csv', sep = ',' )
race.data <- race.data[,c(-5)]
colnames(race.data) <- c('Location', 'White', 'Black', 'Population')
summary(race.data)
```
Se mezclan los datos relacionados con información racial.

```{r}
racial.data <- merge(etnicity.data, race.data, by.x = 'LongName', by.y = 'Location', all.x = TRUE)
racial.data <- racial.data[,-2]
```

Finalmente, para conformar el conjunto de datos sobre el que se realizará el análisis se mezclan todos los datos en un único dataframe teniendo en cuenta la localidad y la fecha a la que pertenece cada observación.

```{r}
data.df <- merge(merged.data, racial.data, by.x=c('Date', 'Province_State'), by.y=c('Date', 'LongName'))
data.df[is.na(data.df)] <- 0
data.df <- data.df[,-3]
summary(data.df)
```
Luego de mezclar toda la información el conjunto de datos a utilizar contiene 2.150 observaciones y 25 variables.

## Análisis descriptivo

```{r warning=FALSE}
set.seed(42)
spl = createDataPartition(data.df$Deaths, p = 0.8, list = FALSE)  # 80% for training

train = data.df[spl,]
test = data.df[-spl,]

dim(train)
summary(train)
```

```{r}
ggplot(train, aes(Deaths)) + geom_density(fill="lightblue") + 
  xlab("Deaths") + ggtitle("Deaths distribution")
```

Según muestra el gráfico la mayor parte de los días en un estado hay entre 0 y 5000 fallecidos aproximadamente. Sin embargo, también se puede observar que hay días donde la cantidad de fallecidos supera los 30.000

Visualicemos la función de densidad en función del logaritmo de la variable objetivo. 

```{r}
ggplot(train, aes(log(Deaths))) + geom_density(fill="lightblue") + 
  xlab("Deaths") + ggtitle("Deaths distribution")
```

```{r}
deaths_by_state = data.df %>% 
  dplyr::group_by(Province_State) %>% 
  dplyr::summarise(deaths = sum(Deaths), population = first(Population)) 

deaths_by_state %>% 
  ggplot(aes(x= Province_State, y = deaths, fill=deaths)) +
  geom_bar(stat='identity') + 
  coord_flip()
```

En el siguiente gráfico se muestra la cantidad de casos confirmados y la cantidad de fallecidos. Los colores se incluyen para diferenciar las curvas en cuanto a las ciudades. Se puede observar que, en general, las muertes tienden a aumentar mientras aumentan los positivos. Debemos tener en cuenta que el gráfico no muestra las muertes que pudieron causar esos casos positivos, para eso habría que hacer el análisis en los próximos 14 días pero sí nos da una medida de cómo pueden estar relacionadas estas variables.

```{r}
data.df %>% 
  ggplot(aes(x = Confirmed, y = Deaths, color = Province_State)) + 
  geom_point() +
  guides(color = FALSE)
```

La siguiente imagen muestra la función de densidad de los fallecidos pero esta vez haciendo una distinción por el estado. Aunque no se puede detectar qué curva pertenece a qué estado específicamente, las curvas muestran un comportamiento similar al la total presentada anteriormente.

```{r}
ggplot(train, aes(log(Deaths))) + geom_density(aes(group=Province_State, colour=Province_State, fill=Province_State), alpha=0.1) + 
  ggtitle("Deaths distribution")
```
```{r}
colnames(data.df)
```
En el conjunto e datos tenemos una gran cantidad de variables. SIn embargo, no todas pueden ser introducidas en el modelo porque esto puede llevar a un sobre-ajuste de los datos por parte de los modelos. En la siguiente imagen se muestra la correlación de algunas de las variables numéricas.


```{r}
numeric_cols = sapply(data.df, is.numeric)
ggcorr_data <- data.df %>% 
  dplyr::select(Confirmed, Deaths, Recovered, Active, Incident_Rate, Total_Test_Results, Testing_Rate, Administered_Fed_LTC, Cases_White, Cases_Black, Hosp_White, Hosp_Black, Hosp_Total)
ggcorr(ggcorr_data, label = T)

```

Tras realizar un analísis descriptivo de los datos, se eliminan del análisis algunas variables para evitar multicolinealidad. En la matriz de correlación se observa que la variable **Active** y **Incident_Rate** tienen una alta correlación positiva por lo tanto es aconsejable eliminar una de las dos. Puesto que la variable Active se puede calcular en función de los casos **Confirmed**, **Recovered** y *Deaths*, la eliminamos. Asimismo, la variable **Incident_Rate** tiene correlación lineal con **Confirmed** por lo que la obviamos también. Existen otros pares de variables que tienen una alta correlación, sin embargo, como nuestro análisis está enfocado en determinar qué factores influyen en la mortalidad de COVID las preservaremos para valorar su aporte a los modelos.


```{r echo=FALSE}
subset <- data.df %>% 
  dplyr::select(Province_State, Deaths, Confirmed, Recovered, Total_Test_Results, Testing_Rate, 
         Administered_Fed_LTC, Cases_White, Cases_Black, Deaths_White, 
         Deaths_Black, Hosp_White, Hosp_Black, Hosp_Total, White, Black)
```


## Modelos de Regresión

En esta sección se desarrollan y comparan entre sí un conjunto de modelos de regresión que dan solución al problema de predicción actual. Aunque hemos comprobado la complejidad de la distribución de los datos, inicialmente se presentan modelos de regresión lineal simples, con el objetivo de comparar y contar con un *baseline* que permita establecer un umbral de mejora. Teniendo en cuenta que en los datos existe un error irreducible que no puede ser explicado por los modelos matemáticos, esto nos permitirá medir el rendimiento de los modelos avanzados que serán presentados posteriormente.


##  Modelos de Regresión Lineal

Los modelos de regresión lineal al expresar la variable objetivo en función del resto de variables nos permiten de forma intuitiva medir la significancia de cada predictor. Por lo tanto, son útiles para seleccionar la cantidad y cuáles variables son adecuadas para explicar. En este trabajo, se desarrollan inicialmente un grupo de modelos lineales para entender la importancia de las variables en la predicción de la variable objetivo.

* El primer modelo tomará el predictor que se ha detectado anteriormente que tiene gran influencia, que es la cantidad de casos confirmados.

```{r}
lm <- lm(log(Deaths) ~ Confirmed, data=train)
summary(lm)
```
El modelo alcanza un R2 del 48%, lo cual reafirma que esta variable es importante para determinar la variable dependiente. 

```{r}
lm.pred.log <- predict(lm, newdata=test)

R2 = cor(log(test$Deaths), lm.pred.log)^2
R2

MAPE = mean(abs(log(test$Deaths)- lm.pred.log)/log(test$Deaths))
MAPE

RMSE <- sqrt(mean((lm.pred.log - log(test$Deaths))^2))
RMSE
```
Para evaluar el modelo se calcula e R2, el Error absoluto medio porcentual (MAPE, del inglés *Mean absolute percentage error*) y el Error cuadrático medio (RMSE, del inglés *Root Mean Squared Error*). El R2 sobre el conjunto de test es más pequeño pero muy similar al de entrenamiento, como es de esperar, porque al utilizar tan pocas variables no puede existir *overfitting* aún.

* El segundo modelo de regresión lineal es el que utiliza todas las variables. No se tienen en cuenta solo algunas que no aportan información más que identificativa a los datos y otras que el modelo completo identifica que están correlacionadas con la variable dependiente y le asigna betas NAs.


```{r}
lm.all <- lm(log(Deaths) ~ .- Lat -Long_ -Population -Black -White, data=train)
summary(lm.all) 
```
Este modelo, que incluye todos los predictores posibles, está sobre-ajustado obteniendo un R2 de un 98%.

```{r}
lm.pred.log.all <- predict(lm.all, newdata=test)

R2 = cor(log(test$Deaths), lm.pred.log.all)^2
R2

MAPE = mean(abs(log(test$Deaths)- lm.pred.log.all)/log(test$Deaths))
MAPE

RMSE <- sqrt(mean((lm.pred.log.all - log(test$Deaths))^2))
RMSE

```
En este modelo el R2 da mayor en el conjunto de test que en el de entrenamiento, lo cual es muy inusual porque significa que el modelo aprendió mejor algo que no le fue enseñado. Sin embargo, la diferencia es muy pequeña. Este sobreajuste nos lleva a que las predicciones sean muy buenas pero los betas son muy malos, y por lo tanto, no pueden ser utilizados para explicar el modelo.

Por último, presentaremos el más simple de los modelos y que predice con un valor fijo. Este modelo es el que usaremos como benchmark, porque es el equivalente a predecir con un número aleatorio.

* El tercer modelo de regresión lineal es el que predice con la media y nos referiremos a él como *naive*.

```{r}
lm.naive <- lm(log(Deaths) ~ 1, data=train)
summary(lm.naive) 
```
```{r}
lm.naive.pred <- predict(lm.naive, newdata=test)

MAPE = mean(abs(log(test$Deaths)- lm.naive.pred)/log(test$Deaths))
MAPE

RMSE <- sqrt(mean((lm.naive.pred - log(test$Deaths))^2))
RMSE
```
En este caso, no se puede utilizar el R2 porque la desviación estándar de una constante es 0 por lo que para posteriores análisis con modelos avanzados solo podremos utilizar el RMSE y el MAPE para comparar con el modelo *naive*. Este modelo nos ayuda a decidir cuán grande es el error irreducible.

## Modelos de Regresión Avanzada

En esta sección nos concentramos en seleccionar dos modelos: un primer modelo, lo llamaremos **Modelo Explicativo** que nos permita interpretar las variables y explicar la predicción y otro modelo, **Modelo Predictivo** que se centre en obtener buenas predicciones.

### Modelo Explicativo

Para el desarrollo del modelo explicativo utilizaremos todo el conjunto de datos. El objetivo es obtener un modelo que involucre las variables más relevantes y que el número de variables sea adecuado para la interpretación. Con el fin de simplificar la explicabilidad las variables no tengan ninguna transformación.

Se desarrollan dos modelos basado en selección de variables, en el primero se propone intuitivamente un modelo y se aplica selección de variables y en el segundo se escogen las variables con el método de *forward* y se aplica lasso.
 

Los modelos llamados **ensembles** se han descartado en la producción de este modelo explicable porque realizan transformaciones a las variables que son muy difíciles de explicar.

Lo importante en un modelo explicativo es que tenga un sesgo (error) pequeño. Por esta razón, para seleccionar el primer modelo partimos del modelo lineal que utiliza todas las variables (visto anteriormente) que tiene un alto R2 ajustado y según los betas hacemos una selección de las variables más significativas sobre las cuales se diseña un nuevo modelo. En este caso, para entrenar y evaluar los modelos se utiliza el método de *cross-validation*.

```{r}
ctrl <- trainControl(method = "repeatedcv", 
                     repeats = 5,
                     number = 10)
```


Al analizar los coeficientes del modelo lineal completo, teniendo en cuenta cada una de las variables se decide el siguiente modelo. Es evidente en el modelo completo que la variable **Province_State** influye mucho en la variable objetivo. Asimismo **Incident_Rate**, pero antes habíamos comprobado que tiene una alta ralación con los casos confirmados. Intentaremos aplicar una interacción entre estas dos variables.

* Modelo intuitivo y selección de variables

```{r}
set.seed(43)
my_lm <- train(log(Deaths) ~ Incident_Rate*Confirmed + Recovered + Province_State + Cases_White*Cases_Black + 
  Deaths_Black + Hosp_Total + Hosp_White + Hosp_Black,
                data = train,
                method = "lm",
                trControl = ctrl,
                preProcess=c('center', 'scale')
)

options(max.print=10000)
all_output <- data.table(Texto=capture.output(summary(my_lm)))
all_output[grepl("R-squared",Texto,fixed=T),]

```
Con este modelo se obtiene un R2 ajustado muy alto, por lo tanto se consigue el objetivo de los modelos explicativos. Apliquemos selección de variables sobre este modelo en base al p-value. Utilizaremos el conjunto de entreanamiento inicial para ver la evolución en la selección.

```{r}
model = log(Deaths) ~ Incident_Rate*Confirmed + Recovered + Province_State + Cases_White*Cases_Black + 
  Deaths_Black + Hosp_Total + Hosp_White + Hosp_Black

linFit <- lm(model, data=train)
ols_step_forward_p(linFit) # forward based on p-value

```
La tabla anterior muestra que a partir de 4 variables ya se alcanza un buen rendimiento. En este caso, nos quedaremos con el modelo porque se observa un ligero aumento en el R2 en la última iteración.

```{r}
plot(ols_step_forward_p(linFit))
```
Intentemos explicar las variables del modelo.

```{r}
linFit
```

Para analizar los coeficientes debemos tener en cuenta que estamos prediciendo el log de la cantidad de muertes. Es evidente que la variable más importante es el estado al que pertenece la observación.

```{r}
exp(cbind(coef(linFit), confint(linFit)))
```
Los coeficientes definen la variación que experimenta la cantidad de fallecidos en un estado al aumentar en una unidad una variable independiente y dejando fijas el resto. A partir de los coeficientes se puede concluir que:

* El estado base sobre el que se construyeron las variables *dummies* es Alabama, lo cual significa que todos los coeficientes de las variables relativas al estado están expresados en función de la cantidad de muertes en el estado de Alabama.
* Por cada persona que muere en el estado de Alabama, aproximadamente la cantidad de fallecidos en California aumenta en 5, en el estado de la Florida aumenta en 9 y así con el resto de las variables.
* La cantidad de muertes aumenta en un 0.9 por cada persona de color negro. En esa misma proporción aumenta cuando una persona blanca se confirma positivo, lo cual quiere decir que no existe diferencia en cuanto al color de la piel de las personas respecto al número de fallecidos.
* La relación del resto de las variables no relacionadas con el estado no aportan un crecimiento ni decrecimiento especial en la variable dependiente.

Aunque este modelo es lineal y sencillo, la variable **Province_State** incluye tantas variables consigo que hace que el resto de variables pierda significancia y no tengan buenos betas. Por esta razón y a pesar de que este modelo cumple con las condiciones de un buen modelo explicativo aplicaremos otra técnica de selección de variables.


* Selección de variables con forward y aplicación de lasso


```{r}
library(olsrr)

smart.model <- log(Deaths) ~ .- Lat -Long_ -Population -Black -White

smart.fit <- lm(smart.model, data=train)

ols_step_forward_p(smart.fit)

```
Tras la aplicación del método forward para la selacción de variables se obtiene el siguiente modelo:

```{r}

forward.model <- log(Deaths) ~ Province_State + Deaths_White + Date + Incident_Rate + 
  Case_Fatality_Ratio + Deaths_Black + Testing_Rate + Hosp_Total + 
  Administered_Fed_LTC_Dose1 + Hosp_Black + Cases_White + Cases_White + Active


lasso_grid <- expand.grid(fraction = seq(.01, 1, length = 20))

lasso.wise.tune <- train(forward.model, data = train,
                    method='lasso',
                    preProc=c('scale','center'),
                    tuneGrid = lasso_grid,
                    trControl=ctrl)

pred.lasso <- predict(lasso.wise.tune, test)
postResample(pred = pred.lasso,  obs = log(test$Deaths))
```
Este modelo obtiene un RMSE de un 0.12 y un R2 del 99% por lo que es un modelo que obtiene muy buenos resultados. Analicemos los coeficientes de los predictores.

```{r}
coef <- predict(lasso.wise.tune$finalModel, type='coef', s = 30)
coef.df <- as.data.frame(coef)
coef.df <- cbind(name = rownames(coef.df), coef.df)

coef.real <- coef.df %>% 
  dplyr::select(name, coefficients) %>% 
  filter(coefficients != 0, !grepl("Province",name)) 

coef.real$coefficients <- exp(coef.real$coefficients)
coef.real

```

Nos concentraremos en los coeficientes de las variables numéricas aunque la variable **Province_State** no se debe eliminar porque aporta mucho. De acuerdo a los coeficientes del modelos diferentes de cero podemos interpretar que:

* Por cada persona de color blanco que muere, aumenta la cantidad de fallecidos en 1.85. O sea, que muere otra persona de otra etnicidad pero con menos probabilidad que si su color de piel es blanco. Lo cual tiene sentido teniendo en cuenta el color de piel de la mayor parte de la población americana.
* Por cada persona negra que muere, la cantidad de fallecidos aumenta en 1.13 La interpretación de estas variables concuerda con la interpretación del modelo anterior de que el color de la piel de una persona no determine la probabilidad de morir por COVID-19.
* Muy relacionada con la variable anterior está la cantidad de casos de personas de color blanco, por cada persona blanca que se enferma aumenta el número de fallecidos en un 1.01. Lo que quiere decir que 100 personas blancas enfermas aumentan en 101 la cantidad de fallecidos.
* En este modelo aparece la variable **Administered_Fed_LTC_Dose1** que corresponde a la cantidad de personas que le ha sido administrada la primera dosis. Se puede notar que no tiene una gran influencia, sin embargo, era de esperar a partir de los pocos datos y del poco tiempo que se lleva aplicando. Conviene hacer un analisis en trabajos futuros sobre la influencia a 30 días.
* Permanece el hecho de que las variables relacionadas con el estado son las que mas peso tienen. En un futuro se recomienda hacer un estudi localizado para evitar este tipo de problemas.


### Modelo Predictivo

Esta sección está dedicada a encontrar un buen modelo para predecir, donde no es tan importante la interpretabilidad de las decisiones. Se plantean varios modelos a utilizar. En este caso se implementan los siguientes modelos:

* Regresión lineal
* Regresión lineal robusta
* Ridge
* Lasso
* Elastic Net
* PLS

Los resultados de cada uno de los modelos serán comparados en función del RMSE y nos quedaremos con el que menor error alcanza. Los modelos de regresión lineal y regresión robusta será probado con todas las variables y con un subconjunto, resultado de aplicar selección de variables stepwise. Por otra parte, el resto solo será entranado utilizando las variables seleccionadas por el tiempo que demora entrenar estos modelos con todas las variables. Además, para la evaluación será utilizado el método de cross-validation, en el caso de regresión lineal y robusta no es necesario porque no tienen hiperparámetros.

Inicialmente se aplica selección de variables retomando nuestros modelos completo y naive. Recordar que aunque le hemos llamado modelo completo algunas variables se han eliminado como fue explicado con anterioridad.

```{r echo=FALSE}

m_step1 <- step(lm.all, lm.naive, direction = 'both')

```
Como resultado de la aplicación del método de stepwise nos quedamos con el siguiente modelo que llamaremos **wise.model**:

```{r}
lm.complete <- log(Deaths) ~ .- Lat -Long_ -Population -Black -White

wise.model <- log(Deaths) ~ Date + Province_State + Confirmed + Recovered + 
    Incident_Rate + Total_Test_Results + Case_Fatality_Ratio + 
    Testing_Rate + Administered_Fed_LTC + Administered_Fed_LTC_Dose1 + 
    Administered_Fed_LTC_Dose2 + Cases_White + Deaths_White + 
    Deaths_Black + Hosp_Total + Hosp_White + Hosp_Black

```


* Regresión lineal (con los modelos lm.complete y wise.model)

```{r}

lm.completed <- lm(lm.complete, data=train)

lm.wise <- lm(wise.model, data=train)

test_results = data.frame(deaths = log(test$Deaths))
test_results$lm.completed = predict(lm.completed, test)
test_results$lm.wise = predict(lm.wise, test)

lm.completed.m <- postResample(pred = test_results$lm.completed, obs = test_results$deaths)
lm.wise.m <- postResample(pred = test_results$lm.wise, obs = test_results$deaths)
```


* Regresión robusta (con los modelos lm.complete y wise.model)

```{r}

rlm.complete <- rlm(lm.complete,data=train)

rlm.wise <- rlm(wise.model,data=train)

test_results$rlm.complete = predict(rlm.complete, test)
test_results$rlm.wise = predict(rlm.wise, test)

rlm.complete.m <- postResample(pred = test_results$rlm.complete, obs = test_results$deaths)
rlm.wise.m <- postResample(pred = test_results$rlm.wise, obs = test_results$deaths)
```

* Ridge

```{r}
ridge_grid <- expand.grid(lambda = seq(0, .1, length = 20))

ridge.wise <- train(wise.model, 
                    data = train,
                    method='ridge',
                    preProc=c('scale', 'center'),
                    tuneGrid = ridge_grid,
                    trControl=ctrl)

plot(ridge.wise)
ridge.wise$bestTune

test_results$ridge.wise <- predict(ridge.wise, test)

ridge.wise.m <- postResample(pred = test_results$ridge.wise, obs = test_results$deaths)

```

* Lasso

```{r}
lasso_grid <- expand.grid(fraction = seq(.01, 1, length = 20))

lasso.wise <- train(wise.model, data = train,
                    method='lasso',
                    preProc=c('scale','center'),
                    tuneGrid = lasso_grid,
                    trControl=ctrl)

plot(lasso.wise)
lasso.wise$bestTune

test_results$lasso.wise <- predict(lasso.wise, test)

lasso.wise.m <- postResample(pred = test_results$lasso.wise,  obs = test_results$deaths)

```
* Elastic Net

```{r}

modelLookup('glmnet')
elastic_grid = expand.grid(alpha = seq(0, .2, 0.01), lambda = seq(0, .1, 0.01))

glmnet.wise <- train(wise.model, data = train,
                     method='glmnet',
                     preProc=c('scale','center'),
                     tuneGrid = elastic_grid,
                     trControl=ctrl)
plot(glmnet.wise)
glmnet.wise$bestTune

test_results$glmnet.wise <- predict(glmnet.wise, test)

glmnet.wise.m <- postResample(pred = test_results$glmnet.wise, obs = test_results$deaths)
```

* PLS

```{r}
pls.wise <- train(wise.model, data = train,
                  method='pls',
                  preProc=c('scale','center'),
                  tuneGrid = expand.grid(ncomp = 2:8),
                  trControl=ctrl)

plot(pls.wise)
pls.wise$bestTune

test_results$pls.wise <- predict(pls.wise, test)

pls.wise.m <- postResample(pred = test_results$pls.wise, obs = test_results$deaths)
```

Teniendo en cuenta el RMSE obtenido por cada uno de los modelos, podemos notar que los modelos lineales que utilizan todas las variables son los que menor error tienen. Sin embargo, al incluir todos los predictores están muy sobre-ajustados y tienen más probabilidades de fallar en datos nuevos (de cierta forma se ha comprobado al evaluar sobre test pero puede pasar que el test y el train en este conjunto de datos sean muy parecidos). Sin embargo, ninguna de los modelos presenta grandes diferencias respecto al resto por lo tanto. Notar que todos los modelos han superado al modelo *naive* que obtuvo un RMSE de 1.441291 y se había establecido como *benchmark*.

```{r echo=FALSE}

models <- t(as.matrix(data.table(
  lm_complete = c(lm.completed.m),
  lm_wise = c(lm.wise.m),
  rlm_complete = c(rlm.complete.m),
  rlm_wise = c(rlm.wise.m),
  ridge_wise = c(ridge.wise.m),
  lasso_wise = c(lasso.wise.m),
  elasticnet_wise = c(glmnet.wise.m),
  pls_wise = c(pls.wise.m)
)))


colnames(models) <- names(lm.completed.m)
models

```
Analicemos la correlación de los modelos.

```{r}
library(GGally)
test_results %>%
  dplyr::select(-deaths) %>%
  ggcorr(palette = "RdBu", label = TRUE) + labs(title = "Correlations between different models")
```
Los modelo tienen una correlación altísima y esto es a causa de los datos. Por lo tanto, en este problema no existe un modelo mejor a simple vista. Por esta razón, se decide combinar dos modelos, se toma el de regresión robusta sobre el conjunto de variables *wise* (que anteriormente habíamos dicho que no era buena idea escoger sólo ese) y lo combinamos con el modelo lasso, que presenta un rendimiento medio (en comparación con el resto) y puede balancear el sobre-ajuste del robusto. Además, lasso al basar se en PCA (Principal Component Analysis) podría aportar explicabilidad a analizar en trabajos futuros.  

```{r}
test_results$comb = (test_results$rlm.wise + test_results$lasso.wise)/2
postResample(pred = test_results$comb,  obs = test_results$deaths)
```
La unión de estos modelos mejora el RMSE sobre el conjunto de test, sin embargo, como fue explicado con anterioridad tampoco se puede garantizar su buen comportamiento en el futuro pero en este punto, es una buena decisión.

#### Cálculo de los intervalos de confianza

Para el cálculo de los intervalos de confianza tomaremos como base el modelo de regresión lineal sobre el conjunto de variables *wise*  porque obtiene buenas métricas pero tampoco demasiado sobre-ajustado y tomaremos un intervalo de confianza al 95% puesto que el error es muy pequeño.


```{r}
wise.model <- log(Deaths) ~ Date + Province_State + Confirmed + Recovered + 
    Incident_Rate + Total_Test_Results + Case_Fatality_Ratio + 
    Testing_Rate + Administered_Fed_LTC + Administered_Fed_LTC_Dose1 + 
    Administered_Fed_LTC_Dose2 + Cases_White + Deaths_White + 
    Deaths_Black + Hosp_Total + Hosp_White + Hosp_Black


lm.wise = lm(wise.model, data = train)

predictions <-predict.lm(lm.wise, newdata=test, interval="prediction", level=0.95)

predictions=as.data.frame(predictions)
predictions$real = test_results$deaths
head(predictions)
```
Veamos cuántas observaciones están fuera del intervalo de confianza. 

```{r}
new.predictions <- predictions %>% 
  mutate(out = factor(if_else(real<lwr | real > upr,1,0)))

mean(new.predictions$out==1)
```
Solo el 2% de las observaciones de la muestra del conjunto de test están fuera del intervalo de confianza. A continuación se muestra de manera gráfica.

```{r}
new.predictions %>% 
ggplot(aes(x=fit, y=real))+
  geom_point(aes(color=out)) + theme(legend.position="none") +
  geom_ribbon(data=new.predictions, aes(ymin=lwr,ymax=upr), alpha=0.3) +
  labs(title = "Prediction intervals", x = "prediction", y="real price")
```
## Predicciones finales

Como se explicó anteriormente, el modelo seleccionado como modelo final para este problema es el modelo combinado. Este modelo es la combinación de un regresor lineal robusto construido sobre el conjunto de variables obtenidas al aplicar el método de *stepwise* y un modelo lasso, el cual también tiene como base la selección de variables. A continuación, se analizan las predicciones obtenidas por este modelo final. 

La distribución de las predicciones es asimétrica, sin embargo el error es más simétrico, lo que implica que el modelo se equivoca similar para los valores por debajo y encima de la media.

```{r}
yhat = test_results$comb
hist(yhat, col="lightblue")

y = test_results$deaths
error = y- yhat
hist(error, col="lightblue")
```

## Conclusiones

En este trabajo se han desarrollado un conjunto de modelos predictivos, algunos enfocados en la explicabilidad de las decisiones y otros en la reducción del error en las predicciones. Se ha analizado un conjunto de datos con información de la situación provocada por la pandemia actual y se han incluido factores externos como información étnica. Los modelos tienen un error muy pequeño, pero esto no garantiza su desempeño en el futuro puesto que por la cantidad de variables que involucran tienen un gran riesgo de sobre-ajuste. En este trabajo solamente se han aplicado modelos de regresión, lo cual puede no ser lo más adecuado dada la naturaleza de los datos. En trabajos futuros sería interesante incluir análisis de series temporales que intuitivamente se adaptan mejor a escenarios temporales como es la información diaria de COVID.











